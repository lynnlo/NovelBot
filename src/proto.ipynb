{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Reshape\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import categorical_crossentropy, mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Charaters        : 44\nTotal Unique Charaters : 9\n"
     ]
    }
   ],
   "source": [
    "# Sort\n",
    "\n",
    "text = open(\"data/goldfish.txt\", \"r\").read()\n",
    "\n",
    "chardict = sorted(list(set(text)))\n",
    "\n",
    "total = len(text)\n",
    "chars = len(chardict)\n",
    "\n",
    "print(\"Total Charaters        :\", total)\n",
    "print(\"Total Unique Charaters :\", chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Chunks : 39\nDictionary :  ['d', 'f', 'g', 'h', 'i', 'l', 'o', 's', '±']\n"
     ]
    }
   ],
   "source": [
    "# Format\n",
    "\n",
    "chunklength = 5\n",
    "step = 1\n",
    "sentences = []\n",
    "characters = []\n",
    "\n",
    "for i in range(0, len(text) - chunklength, step):\n",
    "    sentences.append(text[i : i + chunklength])\n",
    "    characters.append(text[i + chunklength])\n",
    "\n",
    "chunks = len(sentences)\n",
    "print(\"Total Chunks :\", chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample Chunk     :  fish±\nSample Character :  g\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "\n",
    "print(\"Sample Chunk     : \", sentences[4])\n",
    "print(\"Sample Character : \", characters[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Data Values  :  1755\nTotal Label Values :  351\nX Shape : (39, 5, 9)\nY Shape : (39, 1, 9)\n"
     ]
    }
   ],
   "source": [
    "# Format\n",
    "\n",
    "x = np.zeros(chunks * chunklength * chars, np.bool).reshape(chunks, chunklength, chars)\n",
    "y = np.zeros(chunks * 1 * chars, np.bool).reshape(chunks, 1, chars)\n",
    "\n",
    "for i,v in enumerate(sentences):\n",
    "    for a,b in enumerate(v):\n",
    "        x[i][a][chardict.index(b)] = True\n",
    "\n",
    "for i,v in enumerate(characters):\n",
    "    y[i][0][chardict.index(v)] = True\n",
    "\n",
    "print(\"Total Data Values  : \", chunks * chunklength * chars)\n",
    "print(\"Total Label Values : \", chunks * 1 * chars)\n",
    "print(\"X Shape :\", x.shape)\n",
    "print(\"Y Shape :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_5 (LSTM)                (None, 5, 18)             2016      \n_________________________________________________________________\ndense_7 (Dense)              (None, 5, 9)              171       \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 1, 45)             0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 1, 22)             1012      \n_________________________________________________________________\ndense_9 (Dense)              (None, 1, 9)              207       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 1, 9)              0         \n=================================================================\nTotal params: 3,406\nTrainable params: 3,406\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(2 * chars, return_sequences=True, input_shape=(chunklength, chars)))\n",
    "model.add(Dense(chars))\n",
    "model.add(Reshape((1, chunklength * chars)))\n",
    "model.add(Dense((chunklength * chars) / 2))\n",
    "model.add(Dense(chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.0048\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.9060\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8116\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7245\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6444\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5693\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5004\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4403\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3802\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3308\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2944e3d62b0>"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "model.fit(x=x, y=y, batch_size=chucklength, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input shape :  (1, 5, 9)\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "inputdata = x[3].reshape(1, chucklength, chars)\n",
    "\n",
    "prediction = model.predict(inputdata)[0]\n",
    "\n",
    "print(\"Input shape : \", inputdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "mergedprediction = []\n",
    "\n",
    "for a in prediction:\n",
    "    mergedprediction = []\n",
    "    for i,v in enumerate(a):\n",
    "        if not len(mergedprediction) > i:\n",
    "            mergedprediction.append(v)\n",
    "        else:\n",
    "            mergedprediction[i] += v\n",
    "\n",
    "mergedprediction = [mergedprediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['dfish']\n['±']\n"
     ]
    }
   ],
   "source": [
    "# Clean\n",
    "\n",
    "cleaninput = []\n",
    "cleanprediction = []\n",
    "\n",
    "for a in mergedprediction:\n",
    "    bi, bv = 1, -1\n",
    "    for i,v in enumerate(a):\n",
    "        if v > bv:\n",
    "            bv = v\n",
    "            bi = i\n",
    "    cleanprediction.append(chardict[bi])\n",
    "\n",
    "for a in inputdata:\n",
    "    s = []\n",
    "    for b in a:\n",
    "        for i,v in enumerate(b):\n",
    "            if v:\n",
    "                s.append(chardict[i])\n",
    "    cleaninput.append(\"\".join(s))\n",
    "\n",
    "print(cleaninput)\n",
    "print(cleanprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}