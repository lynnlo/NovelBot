{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('Sp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "93867be4e8ec858448828280e19e77c6c69999af4dcd4dfc23ed2f8e75719156"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Dropout, Activation, Reshape\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Charaters        : 26288\nTotal Unique Charaters : 64\n"
     ]
    }
   ],
   "source": [
    "# Sort\n",
    "\n",
    "text = open(\"data/romeoandjuliet.txt\", \"r\").read()\n",
    "text = text[:round(len(text)/2)]\n",
    "\n",
    "chardict = sorted(list(set(text)))\n",
    "\n",
    "total = len(text)\n",
    "chars = len(chardict)\n",
    "\n",
    "print(\"Total Charaters        :\", total)\n",
    "print(\"Total Unique Charaters :\", chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Chunks : 26263\n"
     ]
    }
   ],
   "source": [
    "# Format\n",
    "\n",
    "chunklength = 25\n",
    "step = 1\n",
    "sentences = []\n",
    "characters = []\n",
    "\n",
    "for i in range(0, len(text) - chunklength, step):\n",
    "    sentences.append(text[i : i + chunklength])\n",
    "    characters.append(text[i + chunklength])\n",
    "\n",
    "chunks = len(sentences)\n",
    "print(\"Total Chunks :\", chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sample Chunk     :  ROMEO AND JULIET\n\nby Will\nSample Character :  i\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "\n",
    "print(\"Sample Chunk     : \", sentences[0])\n",
    "print(\"Sample Character : \", characters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Data Values  :  42020800\nTotal Label Values :  1680832\nX Shape : (26263, 25, 64)\nY Shape : (26263, 1, 64)\n"
     ]
    }
   ],
   "source": [
    "# Format\n",
    "\n",
    "x = np.zeros(chunks * chunklength * chars, np.bool).reshape(chunks, chunklength, chars)\n",
    "y = np.zeros(chunks * 1 * chars, np.bool).reshape(chunks, 1, chars)\n",
    "\n",
    "for i,v in enumerate(sentences):\n",
    "    for a,b in enumerate(v):\n",
    "        x[i][a][chardict.index(b)] = True\n",
    "\n",
    "for i,v in enumerate(characters):\n",
    "    y[i][0][chardict.index(v)] = True\n",
    "\n",
    "print(\"Total Data Values  : \", chunks * chunklength * chars)\n",
    "print(\"Total Label Values : \", chunks * 1 * chars)\n",
    "print(\"X Shape :\", x.shape)\n",
    "print(\"Y Shape :\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 25, 128)           98816     \n_________________________________________________________________\ndense (Dense)                (None, 25, 64)            8256      \n_________________________________________________________________\ndropout (Dropout)            (None, 25, 64)            0         \n_________________________________________________________________\nreshape (Reshape)            (None, 1, 1600)           0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1, 64)             102464    \n_________________________________________________________________\nactivation (Activation)      (None, 1, 64)             0         \n=================================================================\nTotal params: 209,536\nTrainable params: 209,536\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(2 * chars, return_sequences=True, input_shape=(chunklength, chars)))\n",
    "model.add(Dense(chars))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Reshape((1, chunklength * chars)))\n",
    "model.add(Dense(chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "1051/1051 [==============================] - 24s 23ms/step - loss: 2.0598\n",
      "Epoch 2/4\n",
      "1051/1051 [==============================] - 29s 27ms/step - loss: 1.9819\n",
      "Epoch 3/4\n",
      "1051/1051 [==============================] - 31s 30ms/step - loss: 1.9108\n",
      "Epoch 4/4\n",
      "1051/1051 [==============================] - 34s 32ms/step - loss: 1.8486\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d5059df70>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "model.fit(x=x, y=y, batch_size=chunklength, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Input\n",
    "\n",
    "userinput = chardict[0] * 5 or sentences[0]\n",
    "\n",
    "userdata = np.zeros(chunklength * chars, np.bool).reshape(1, chunklength, chars)\n",
    "\n",
    "for i,v in enumerate(userinput):\n",
    "        userdata[0][i][chardict.index(v)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input shape :  (1, 25, 64)\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "inputdata = x[53].reshape(1, chunklength, chars)\n",
    "\n",
    "prediction = model.predict(inputdata)[0]\n",
    "\n",
    "print(\"Input shape : \", inputdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean\n",
    "\n",
    "totalprediction = \"\"\n",
    "length = 250\n",
    "\n",
    "for i in range(length):\n",
    "\n",
    "    cleaninput = []\n",
    "    cleanprediction = []\n",
    "\n",
    "    for a in prediction:\n",
    "        bi, bv = 1, -1\n",
    "        for i,v in enumerate(a):\n",
    "            if v > bv:\n",
    "                bv = v\n",
    "                bi = i\n",
    "        cleanprediction.append(chardict[bi])\n",
    "\n",
    "    for a in inputdata:\n",
    "        s = []\n",
    "        for b in a:\n",
    "            for i,v in enumerate(b):\n",
    "                if v:\n",
    "                    s.append(chardict[i])\n",
    "        cleaninput.append(\"\".join(s))\n",
    "\n",
    "    # New Prediction\n",
    "\n",
    "    newinput = \"\".join(list(i for i in cleaninput[0])[1:]) + cleanprediction[0]\n",
    "\n",
    "    userdata = np.zeros(chunklength * chars, np.bool).reshape(1, chunklength, chars)\n",
    "\n",
    "    for i,v in enumerate(newinput):\n",
    "            userdata[0][i][chardict.index(v)] = True\n",
    "    inputdata = userdata\n",
    "\n",
    "    prediction = model.predict(inputdata)[0]\n",
    "\n",
    "    totalprediction += cleanprediction[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "he to leap and sto the with his the farle the with his the part as and and the will at me the with his the tarl as and sto the with his light fare the with his the wall at you the wall at the to hear wellow the to the tare the faither the the with th\n"
     ]
    }
   ],
   "source": [
    "print(totalprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}